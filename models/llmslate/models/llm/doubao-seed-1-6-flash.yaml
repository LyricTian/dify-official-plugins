model: doubao-seed-1-6-flash
label:
  zh_Hans: Doubao-Seed-1.6-flash
  en_US: Doubao-Seed-1.6-flash
model_type: llm
features:
- tool-call
- stream-tool-call
- agent-thought
- vision
model_properties:
  mode: chat
  context_size: 256000
parameter_rules:
- name: temperature
  use_template: temperature
- name: max_tokens
  use_template: max_tokens
  type: int
  default: 16000
  min: 1
  max: 256000
  help:
    zh_Hans: 指定生成结果长度的上限。如果生成结果截断，可以调大该参数。
    en_US: Specifies the upper limit on the length of generated results. If the generated
      results are truncated, you can increase this parameter.
- name: top_p
  use_template: top_p
- name: top_k
  label:
    zh_Hans: 取样数量
    en_US: Top k
  type: int
  help:
    zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
    en_US: Only sample from the top K options for each subsequent token.
  required: false
- name: frequency_penalty
  use_template: frequency_penalty
- name: response_format
  label:
    zh_Hans: 回复格式
    en_US: Response Format
  type: string
  help:
    zh_Hans: 指定模型必须输出的格式
    en_US: Specifying the format that the model must output
  required: false
  options:
  - text
  - json_object
pricing:
  input: '0.18'
  output: '1.8'
  unit: '0.000001'
  currency: RMB
  input_cached: '0'
  billing_type: CONTEXT
  context_prices:
  - input_price: 720000
    output_price: 7200000
    gt_context_window: 128000
    input_cached_price: 0
  - input_price: 360000
    output_price: 3600000
    gt_context_window: 32000
    input_cached_price: 0
  - input_price: 180000
    output_price: 1800000
    gt_context_window: 0
    input_cached_price: 0
